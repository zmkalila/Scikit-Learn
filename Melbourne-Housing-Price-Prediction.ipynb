{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":38454,"sourceType":"datasetVersion","datasetId":2709}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zmkalila/melbourne-housing-price-prediction?scriptVersionId=200049612\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Getting started\n\nI make this notebook for learning purposes based on the codes in this YouTube lesson:  \nhttps://youtu.be/DY10uyDy3vQ?si=Du8dIucJMRAq9B2L with my own code modifications and markdowns here and there.","metadata":{}},{"cell_type":"markdown","source":"## Import module","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset from Kaggle to Jupyter Notebook directory","metadata":{}},{"cell_type":"code","source":"!kaggle datasets download -d dansbecker/melbourne-housing-snapshot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unzip dataset file to the same directory","metadata":{}},{"cell_type":"code","source":"import zipfile\nz= zipfile.ZipFile('melbourne-housing-snapshot.zip')\nz.extractall()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting DataFrame display","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_columns', 30)\npd.set_option('display.max_rows', 30)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read csv file as Pandas DataFrame","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('melb_data.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"markdown","source":"## Dimension of dataset","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## List of dataset columns","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary of dataset","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's say we want to find the biggest Landsize in the dataset:","metadata":{}},{"cell_type":"code","source":"df.describe().loc['max', 'Landsize']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()['Landsize']['max']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Landsize'].max()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data type of each column","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of null/NaN/missing values in DataFrame","metadata":{}},{"cell_type":"code","source":"df.isnull().sum().to_frame() # alternative: df.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data cleaning","metadata":{}},{"cell_type":"markdown","source":"## Replace NaN (missing values) with 0","metadata":{}},{"cell_type":"code","source":"df.fillna(0, inplace=True)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Change column data types","metadata":{}},{"cell_type":"code","source":"list = ['Price', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'YearBuilt', 'Propertycount']\n\ndf[list] = df[list].astype(int) # change from float to integer\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning Basics","metadata":{}},{"cell_type":"markdown","source":"## Prediction target (output) selection\n\nSelect a part of the dataset that we want to predict later using the Machine Learning model that we build.","metadata":{}},{"cell_type":"code","source":"y = df['Price']\ny.head().to_frame()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features (input) selection\n\nSelect part(s) of the dataset that we want to use as the material for Machine Learning process to predict the target.","metadata":{}},{"cell_type":"code","source":"features = ['Rooms', 'Bedroom2', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\nX = df[features]\nX.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building model","metadata":{}},{"cell_type":"markdown","source":"### Model selection\n\nBuild machine learning model using Decision Tree Regressor.\n\nDecision Tree model can be used for classification and regression problems, but because in this case the prediction target is `price` (which is numerical data), then regression is used.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Configure model","metadata":{}},{"cell_type":"code","source":"housing_model = DecisionTreeRegressor(random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training model\n\nmethod `.fit()` is used for the machine to \"learn\" as if  \n- `X` is the problems/questions to be solved, and\n- `y` is the answer key.","metadata":{}},{"cell_type":"code","source":"housing_model.fit(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Doing prediction","metadata":{}},{"cell_type":"code","source":"housing_model.predict(X.head()) # the predicted value","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head().to_frame() # the real value","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see above, the predicted values and the real values are exactly the same.  \n\nThis happens because the dataset is NOT split into training and testing dataset (the way it should've been done), which means the machine was being tested on the same exact material as the ones it learned, thus it gives out perfect prediction result.\n\nLater on, the dataset has to be split into two parts: training and testing set.","metadata":{}},{"cell_type":"markdown","source":"## Model evaluation","metadata":{}},{"cell_type":"markdown","source":"### Importing evaluation metric (`mean_absolute_error`)","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat = housing_model.predict(X)\n# in machine learning, usually prediction result is assigned to variable named 'y_hat'\n\nmean_absolute_error(y, y_hat)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting dataset into Training and Testing dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting dataset into two parts","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Think of it as:  \n- `X_train` : practice problems (learning materials)\n- `y_train`  : answer keys to practice problems\n- `X_test` : examination problems (testing materials)\n- `y_test`  : answer keys to the examination problems\n\nAnd as we all know, a good test/examination is the one that doesn't have high similarity with the practice problems, thus the dataset has to be split into training and testing.","metadata":{}},{"cell_type":"markdown","source":"### Configure and train model","metadata":{}},{"cell_type":"code","source":"housing_model = DecisionTreeRegressor(random_state=1)\nhousing_model.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model evaluation","metadata":{}},{"cell_type":"code","source":"y_hat = housing_model.predict(X_test)\nmean_absolute_error(y_test, y_hat)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model optimization","metadata":{}},{"cell_type":"code","source":"def get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(X_train, y_train)\n    y_hat = model.predict(X_test)\n    mae = mean_absolute_error(y_test, y_hat)\n    return mae","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing mean absolute error with varying values of `max_leaf_nodes` to find the best value\n\nIn DecisionTreeRegressor model, the adjustable parameter is the value of `max_leaf_nodes` thus it is the one being varied.","metadata":{}},{"cell_type":"code","source":"for max_leaf_nodes in [5, 50, 500, 5000]:\n    leaf_mae = get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test)\n    print(f'Max leaf nodes: {max_leaf_nodes} \\t Mean Absolute Error: {int(leaf_mae)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Higher `max_leaf_nodes` is NOT equivalent to lower error (=better performance).  \n\nAs seen above, mean absolute error for `max_leaf_nodes=500` is lower than model with `max_leaf_nodes=5000`, meaning it has better performance.","metadata":{}},{"cell_type":"markdown","source":"## Data exploration with Random Forest","metadata":{}},{"cell_type":"markdown","source":"### Importing RandomForestRegressor\n\nRandomForest is a popular Machine Learning Model, and is a development from the DecisionTree model.\n\nNotice how it's called \"Tree\" and the other one's called \"Forest\",  \nit's because RandomForest consists of a group of DecisionTree.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestRegressor(n_estimators=100, random_state=1)\n# n_estimators is the number of DecisionTree within the RandomForest\n\nrf_model.fit(X_train, y_train)\ny_hat = rf_model.predict(X_test)\nprint(f'Mean Absolute Error: {int(mean_absolute_error(y_test, y_hat))}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Turns out, the Mean Absolute Error of RandomForest is lower (thus the model has better performance) in comparison to DecisionTree model.","metadata":{}}]}